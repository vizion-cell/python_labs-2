# viz

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
name = (input("–ò–º—è: "))
age = int(input("–í–æ–∑—Ä–∞—Å—Ç: "))
print (f"–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age+1}.")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/01.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
a = float(input("a: "))
b = float(input("b: "))
sum = a + b
average = sum /2
print (f"sum - {round(sum, 2)}; average - {round(average, 2)}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab01/02.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 3
```python
price = float(input("Price: "))
discount = float(input("Discount: "))
vat = float(input("VAT: "))
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print (f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} ‚ÇΩ\n"
       f"–ù–î–°: {vat_amount:.2f} ‚ÇΩ\n"
       f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ: {total:.2f} ‚ÇΩ\n")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab01/03.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 4
```python
m = int(input("–¶–µ–ª—ã–µ –º–∏–Ω—É—Ç—ã: "))
hour = m // 60
min = m % 60
print (f"{hour}:{min:02d}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](./images/lab01/04.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 5
```python
FIO = input("–§–ò–û: ")
FIO = ' '.join(FIO.split())
splitwords = FIO.split()
FIO_2 = FIO.strip()
fletters = []
str_fletters = '' 
for word in splitwords:
    fletters.append(word[0].upper())
for letter in fletters:
    str_fletters += letter
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {str_fletters}")
print(f"–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {len(FIO_2)}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](./images/lab01/05.png)# python_labs



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:    
    if not nums:    
        raise ValueError("–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç")    
    return (min(nums),max(nums))    
    
def unique_sorted(nums: list[float | int]) -> list[float | int]:     
    return sorted(set(nums)) if nums else []       

def flatten(mat: list[list | tuple]) -> list:   
    if not mat: 
        raise ValueError("–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç")   

    result = []
    for row in mat:
        if not isinstance(row,(list,tuple)): 
            raise TypeError("—Å—Ç—Ä–æ–∫–∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞ —Å—Ç—Ä–æ–∫ –º–∞—Ç—Ä–∏—Ü—ã")  
        result.extend(row)  
    return result 
    


def show_min_max(x):
    try:
        print(x, "‚Üí", min_max(x))
    except ValueError:
        print(x, "‚Üí ValueError")

def show_unique_sorted(x):
    print(x, "‚Üí", unique_sorted(x))

def show_flatten(x):
    try:
        print(x, "‚Üí", flatten(x))
    except TypeError:
        print(x, "‚Üí TypeError")


show_min_max([1337, -1, 6, 5, 0])
show_min_max([428])
show_min_max([-5, -29, -9])
show_min_max([])
show_min_max([1.55, 2, 2.1, -3.9])

print()

show_unique_sorted([1337, 2, 4, 2, 1337])
show_unique_sorted([])
show_unique_sorted([-2, -2, 0, 3, 3])
show_unique_sorted([1.0, 1, 2.5, 2.5, 0])

print()

show_flatten([[1, 2], [8, 9]])
show_flatten([[1], [23, 73], (43, 53)])
show_flatten([[1], [6, 5], [1]])
show_flatten([[1, 2], "strcmp"])
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab02/arrays.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
def transpose(mat: list[list[int | float]]) -> list[list[int | float]]:
    if not mat:
        return []
    
    for i in range(len(mat) - 1):
        if len(mat[i]) != len(mat[i + 1]):
            raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–≤–∞–Ω–∞—è")

    result = []
    for i in range(len(mat[0])):
        new_list = []
        for k in range(len(mat)):
            new_list.append(mat[k][i])  
        result.append(new_list)         
    return result 



def row_sums(mat: list[list[int | float]]) -> list[float]:
    if not mat:
        return []
    for i in range(len(mat) - 1):
        if len(mat[i]) != len(mat[i + 1]):  
            raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–≤–∞–Ω–∞—è")
    result = []
    for row in mat:
        s = 0.0
        for x in row:
            s += x
        result.append(s)
    return result


def col_sums(mat: list[list[int | float]]) -> list[float]:
    if not mat:
        return []
    for i in range(len(mat) - 1):
        if len(mat[i]) != len(mat[i + 1]):
            raise ValueError("–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–≤–∞–Ω–∞—è")
    rows = len(mat)        
    cols = len(mat[0]) 
    result = [0.0] * cols
    for j in range(cols):
        s = 0.0
        for i in range(rows):
            s += mat[i][j]
        result[j] = s
    return result



def show_transpose(m):
    try:
        print(f"{str(m):<25} ‚Üí {transpose(m)}")
    except ValueError:
        print(f"{str(m):<25} ‚Üí ValueError")

def show_row_sums(m):
    try:
        print(f"{str(m):<25} ‚Üí {row_sums(m)}")
    except ValueError:
        print(f"{str(m):<25} ‚Üí ValueError")

def show_col_sums(m):
    try:
        print(f"{str(m):<25} ‚Üí {col_sums(m)}")
    except ValueError:
        print(f"{str(m):<25} ‚Üí ValueError")

show_transpose([[11, 12, 13], [41, 52, 63]])   
show_transpose([[-3, 3], [7, -7]])    
show_transpose([[0, 0], [0, 0]]) 
show_transpose([[1, 2], [3]])  
print()
show_row_sums([[1, 12, 23], [44, 65, 86]])   
show_row_sums([[-1, 5], [2, -10]])    
show_row_sums([[1, 1], [1, 1]]) 
show_row_sums([[1, 2], [3]])  
print()
show_col_sums([[1, 99, 366], [42, 52, 61]])   
show_col_sums([[-1, 4], [8, -10]])    
show_col_sums([[0, 0], [0, 0]]) 
show_col_sums([[1, 2], [5]])    
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab02/matrix.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 3
```python
def format_record(rec: tuple[str, str, float]) -> str:
    fio, group, gpa = rec
    parts = fio.split()
    if len(parts) < 2:
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –§–ò–û")
    surname = parts[0].capitalize()
    initial = "".join(w[0].upper()+"." for w in parts [1:3])
    group1 = " ".join(group.split()).upper()
    if not group1:
        raise ValueError("–ì—Ä—É–ø–ø–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—É—Å—Ç–æ–π")
    if not isinstance(gpa,(int,float)):
        raise TypeError("GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º")
    gpa_str = f"{float(gpa):.2f}"

    return f"{surname} {initial}, –≥—Ä. {group1}, GPA {gpa_str}"

print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BVIT-25", 4.6)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "–ò–ö–í–û-12", 5.0)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "–ò–ö–í–û-12", 5.0)))
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞   –∞–Ω–Ω–∞  —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))
print(format_record((" ", "BVIT-25", 4.6)))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab02/tuples.png)# python_labs

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3

### –ó–∞–¥–∞–Ω–∏–µ –ê
```
import re

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    s=text
    if casefold :
        s=s.casefold()
    if yo2e :
        s=s.replace("—ë","–µ").replace("–Å","–ï")
    s=s.replace("\t"," ").replace("\r"," ").replace("\n"," ")
    s = ' '.join(s.split())
    s=s.strip()

    return s

def tokenize(text: str) -> list[str]:
    pattern= r'\w+(?:-\w+)*'
    tokenstext = re.findall(pattern, text)

    return tokenstext

def count_freq(tokens: list[str]) -> dict[str, int]:
    counts={}
    for word in tokens:
        counts[word]=counts.get(word,0)+1
    return counts

def sort_key(item):
    return [-item[1], item[0]]

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    sorted_freq= sorted(freq.items(),key=sort_key)
    top_n=[]

    for i in range(min(n, len(sorted_freq))):
        top_n.append((sorted_freq[i][0], sorted_freq[i][1]))

    return top_n

def summary(text):
    normalized_text = normalize(text)

    tokens = tokenize(normalized_text)

    total_words = len(tokens)
    freq_sorted = count_freq(tokens)
    unique_words = len(freq_sorted)
    top = top_n(freq_sorted, 5)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
    print("–¢–æ–ø-5:")

    for word, count in top:
        print(f"{word}:{count}")
```
–û—Ç–¥–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å —Ç–µ—Å—Ç-–∫–µ–π—Å–∞–º–∏
```
import sys
import os

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from src.lib.text import *

print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞", yo2e=True))
print(normalize("Hello\r\nWorld"))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))


print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

print(top_n(count_freq(["a", "b", "a", "c", "b", "a"]), n=2))
print(top_n(count_freq(["bb", "aa", "bb", "aa", "cc"]), n=2))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab03/text.png)# python_labs
### –ó–∞–¥–∞–Ω–∏–µ B
```
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
from src.lib.text import normalize, tokenize, count_freq, top_n

def main():
    input_text = sys.stdin.readline()


    text_norm = normalize(input_text)
    tokens = tokenize(text_norm)
    freq = count_freq(tokens)

    words_total = len(tokens)
    unique_words = len(freq)

    top_words = top_n(freq, 5)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {words_total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
    print("–¢–æ–ø-5:")
    for word, count in top_words:
        print(f"{word}:{count}")

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab03/text_stats.png)# python_labs

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4

### –ó–∞–¥–∞–Ω–∏–µ A
```
from pathlib import Path
from typing import Iterable, Sequence
import csv

# –†–∏–¥–∏–Ω–≥
def read_text(path: str, encoding: str = "utf-8") -> str:
    p = Path(path)
    try:
        return p.read_text(encoding=encoding) 
    except UnicodeDecodeError:
        print("–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏.")
        exit(1)  

# –í—Ä–∞–π—Ç–∏–Ω–≥
def write_csv(rows: Iterable[Sequence], path: str | Path, header: list[str] = None) -> None:
    p = Path(path)
    with p.open("w", newline="", encoding="utf-8") as f: 
        writer = csv.writer(f)
        if header:
            writer.writerow(header)  
        writer.writerows(rows)  
```
### –ó–∞–¥–∞–Ω–∏–µ B
```
import csv
import re
from pathlib import Path
from collections import Counter

# –†–∏–¥–∏–Ω–≥
def read_text(path: str) -> str:
    p = Path(path)
    try:
        with p.open("r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"–§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return ""

# –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
def normalize(text: str) -> str:
    return text.lower().replace("\n", " ").replace("\r", " ")

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞
def tokenize(text: str) -> list[str]:
    WORD_RE = re.compile(r"\b\w+\b")  # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª–æ–≤
    return WORD_RE.findall(text)

# –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã
def count_freq(tokens: list[str]) -> dict[str, int]:
    return dict(Counter(tokens))

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda item: item[1], reverse=True)

# –§—É–Ω–∫—Ü–∏–∏ –∑–∞–ø–∏—Å–∏ –≤ csv 
def write_csv(rows: list[list[str]], path: str, header=None):
    with open(path, mode="w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        if header:
            writer.writerow(header)
        writer.writerows(rows)

# –í—Å–µ –≤–º–µ—Å—Ç–µ
def process_and_write_text():
    text = read_text("src/data/lab04/input.txt")
    normalized_text = normalize(text)
    tokens = tokenize(normalized_text)
    freq = count_freq(tokens)
    sorted_freq = sorted_word_counts(freq)



    # –ó–∞–ø–∏—Å—å –≤ csv
    write_csv(sorted_freq, "src/data/lab04/report.csv", header=["word", "count"])

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    process_and_write_text()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1][./images/lab04/text_report.png]# python_labs


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5

### –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (people.json)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab05/people.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ A
```
import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    json_file = Path(json_path)
    csv_file = Path(csv_path)

    if json_file.suffix != '.json':
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {json_path}. –û–∂–∏–¥–∞–µ—Ç—Å—è .json")
    
    if not json_file.exists():
        raise FileNotFoundError(f"JSON —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}")
# –†–∏–¥–∏–Ω–≥ –∏–∑ json
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if not data:
        raise ValueError(f"–ü—É—Å—Ç–æ–π JSON —Ñ–∞–π–ª: {json_path}")

# –í—Ä–∞–π—Ç–∏–Ω–≥ –≤ csv
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        if data:
            writer = csv.DictWriter(f, fieldnames=data[0].keys())
            writer.writeheader()
            writer.writerows(data)
        else:
            raise ValueError(f"–ü—É—Å—Ç–æ–π JSON —Ñ–∞–π–ª: {json_path}")
        
    print(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ CSV: {csv_path}")

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
json_file_path = 'src/data/samples/people.json' 
csv_file_path = 'src/data/out/people_from_json.csv'  

json_to_csv(json_file_path, csv_file_path)
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab05/people_from_json.png)# python_labs


### –ó–∞–¥–∞–Ω–∏–µ B
```
import csv
from pathlib import Path

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    csv_file = Path(csv_path)
    xlsx_file = Path(xlsx_path)

    if csv_file.suffix != '.csv':
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {csv_path}. –û–∂–∏–¥–∞–µ—Ç—Å—è .csv")
    
    if not csv_file.exists():
        raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
# –†–∏–¥–∏–Ω–≥ –∏–∑ csv
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        rows = list(reader)

    if not rows:
        raise ValueError(f"–ü—É—Å—Ç–æ–π CSV —Ñ–∞–π–ª: {csv_path}")
# –í—Ä–∞–π—Ç–∏–Ω–≥ –≤ xlsx
    with open(xlsx_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerows(rows)
    
    print(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ XLSX: {xlsx_path}")

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
csv_file_path = 'src/data/out/people_from_json.csv'  
xlsx_file_path = 'src/data/out/people_from_csv.xlsx'  

csv_to_xlsx(csv_file_path, xlsx_file_path)
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab05/people_from_csv.png)# python_labs

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6

### –ó–∞–¥–∞–Ω–∏–µ 1
```
import argparse
import re
from collections import Counter

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
def cat(input_file, number_lines=False):
    try:
        with open(input_file, 'r', encoding='utf-8') as file:
            for idx, line in enumerate(file, 1):
                if number_lines:
                    print(f"{idx}: {line.strip()}")
                else:
                    print(line.strip())
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤
def stats(input_file, top=5):
    try:
        with open(input_file, 'r', encoding='utf-8') as file:
            text = file.read().lower()
            words = re.findall(r'\w+', text)
            word_counts = Counter(words)
            most_common = word_counts.most_common(top)
            print(f"–¢–æ–ø {top} —Å–∞–º—ã—Ö —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è —Å–ª–æ–≤:")
            for word, count in most_common:
                print(f"{word}: {count}")
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")

def main():
    parser = argparse.ArgumentParser(description="CLI —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏")
    subparsers = parser.add_subparsers(dest="command")

    # –ü–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat ‚Äî –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    # –ü–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats ‚Äî –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤
    stats_parser = subparsers.add_parser("stats", help="–ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤")
    stats_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É")
    stats_parser.add_argument("--top", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è —Å–ª–æ–≤")

    args = parser.parse_args()

    if args.command == "cat":
        cat(args.input, args.n)
    elif args.command == "stats":
        stats(args.input, args.top)

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/cat.png)# python_labs
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab06/stats.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ 2
```
import argparse
import json
import csv

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è JSON –≤ CSV
def json2csv(input_file, output_file):
    try:
        with open(input_file, 'r', encoding='utf-8') as json_file:
            data = json.load(json_file)
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:
            writer = csv.writer(csv_file)
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–∏–∑ –∫–ª—é—á–µ–π –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è)
            writer.writerow(data[0].keys())
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            for entry in data:
                writer.writerow(entry.values())
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ JSON –≤ CSV –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {output_file}")
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV –≤ JSON
def csv2json(input_file, output_file):
    try:
        with open(input_file, 'r', encoding='utf-8') as csv_file:
            reader = csv.reader(csv_file)
            headers = next(reader)  # –ó–∞–≥–æ–ª–æ–≤–∫–∏ (–ø–µ—Ä–≤—ã–π —Ä—è–¥)
            rows = [dict(zip(headers, row)) for row in reader]
        
        with open(output_file, 'w', encoding='utf-8') as json_file:
            json.dump(rows, json_file, indent=4)
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ CSV –≤ JSON –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {output_file}")
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    subparsers = parser.add_subparsers(dest="cmd")

    # –ü–æ–¥–∫–æ–º–∞–Ω–¥–∞ json2csv ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ JSON –≤ CSV
    json2csv_parser = subparsers.add_parser("json2csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV")
    json2csv_parser.add_argument("--in", dest="input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É JSON")
    json2csv_parser.add_argument("--out", dest="output", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É CSV")

    # –ü–æ–¥–∫–æ–º–∞–Ω–¥–∞ csv2json ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ CSV –≤ JSON
    csv2json_parser = subparsers.add_parser("csv2json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON")
    csv2json_parser.add_argument("--in", dest="input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É CSV")
    csv2json_parser.add_argument("--out", dest="output", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É JSON")

    args = parser.parse_args()

    if args.cmd == "json2csv":
        json2csv(args.input, args.output)
    elif args.cmd == "csv2json":
        csv2json(args.input, args.output)

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/convert.png)# python_labs
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab06/people_json.png)# python_labs
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab06/people_csv.png)# python_labs

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7

### –ó–∞–¥–∞–Ω–∏–µ test_text.py
```
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize_basic(source, expected):
    assert normalize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("–≥–æ—à–∞,—Å–∞—à–∞,–≤–∞—Å—é—Ç–∫–∞!", ["–≥–æ—à–∞", "—Å–∞—à–∞", "–≤–∞—Å—é—Ç–∫–∞"]),
        (
            "email@example.com website.shh",
            ["email", "example", "com", "website", "shh"],
        ),
        ("!", []),
    ],
)
def test_tokenize_basic(source, expected):
    assert tokenize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        (
            ["—è", "–Ω–µ–Ω–∞–≤–∏–∂—É", "python", "—è", "–Ω–µ–Ω–∞–≤–∏–∂—É", "–∫–æ–¥"],
            {"—è": 2, "–Ω–µ–Ω–∞–≤–∏–∂—É": 2, "python": 1, "–∫–æ–¥": 1},
        ),
        (["four", "five", "six"], {"four": 1, "five": 1, "six": 1}),
        (["xdxd", "xd", "xdxd", "xdxdxd", "xdxd"], {"xdxd": 3, "xd": 1, "xdxdxd": 1}),
    ],
)
def test_count_freq_and_top_n(source, expected):
    assert count_freq(source) == expected


@pytest.mark.parametrize(
    "source, n, expected",
    [
        ({"—è": 2, "–ª—é–±–ª—é": 2, "python": 1, "–∫–æ–¥": 1}, 2, [("–ª—é–±–ª—é", 2), ("—è", 2)]),
        ({"–æ–¥–∏–Ω": 1, "–¥–≤–∞": 1, "—Ç—Ä–∏": 1}, 2, [("–¥–≤–∞", 1), ("–æ–¥–∏–Ω", 1)]),
        ({"lala": 3, "la": 1, "lalala": 1}, 2, [("lala", 3), ("la", 1)]),
    ],
)
def test_top_n_tie_breaker(source, n, expected):
    assert top_n(source, n) == expected
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab07/test_text.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ test_json_csv.py
```
import pytest
import json, csv
from pathlib import Path
from src.lab05.json_csv import json_to_csv
from src.lab05.csv_json import csv_to_json


def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    json_data = [
        {"name": "Vasia", "age": 54},
        {"name": "Bob", "age": 15},
    ]
    src.write_text(
        json.dumps(json_data, ensure_ascii=False, indent=2), encoding="utf-8"
    )
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())


def test_json_to_csv_empty_raises(tmp_path: Path):
    src = tmp_path / "empty.json"
    dst = tmp_path / "out.csv"
    empty_json_data = []
    src.write_text(json.dumps(empty_json_data), encoding="utf-8")

    with pytest.raises(ValueError):
        json_to_csv(str(src), str(dst))


def test_json_to_csv_invalid_json(tmp_path: Path):
    src = tmp_path / "invalid.json"
    dst = tmp_path / "out.csv"
    invalid_json_data = (
        '{"name": "Vasia", "age": 54'  
    )
    src.write_text(invalid_json_data, encoding="utf-8")

    with pytest.raises(ValueError):
        json_to_csv(str(src), str(dst))


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    csv_data = """name,age
Vasia,54
Bob,15"""

    src.write_text(csv_data, encoding="utf-8")
    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        result_data = json.load(f)

    assert isinstance(result_data, list) and len(result_data) == 2
    assert set(result_data[0]) == {"name", "age"}


def test_file_not_exist(tmp_path: Path):
    with pytest.raises(FileNotFoundError):
        csv_to_json("nope.csv", "out.json")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab07/test_json_csv.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ black
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab07/black.png)# python_labs


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8

### –ó–∞–¥–∞–Ω–∏–µ –ê
```
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Student:
    fio: str          
    birthdate: str    
    group: str        
    gpa: float        

    def __post_init__(self):
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã —Ä–æ–∂–¥–µ–Ω–∏—è: {self.birthdate}")
        
        if not (0 <= self.gpa <= 10):
            raise ValueError(f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 10, –Ω–æ –ø–æ–ª—É—á–µ–Ω: {self.gpa}")

    def age(self) -> int:
        birth_year = int(self.birthdate[:4])
        current_year = datetime.today().year
        return current_year - birth_year

    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }

    @classmethod
    def from_dict(cls, data: dict) -> 'Student':
        return cls(fio=data["fio"], birthdate=data["birthdate"], group=data["group"], gpa=data["gpa"])

    def __str__(self):
        # –î–ª—è –∫—Ä–∞—Å–æ—Ç—ã
        return f"Student(fio={self.fio}, group={self.group}, gpa={self.gpa})"
```
## —Ç–µ—Å—Ç
```
from src.lab08.models import Student  

def test_age():
    student = Student("–ú–∞–π–∫ –¢–∞–π—Å–æ–Ω", "1966-06-30", "–ë–ò–í–¢-25-1", 5.0)
    assert student.age() == 59 

def test_to_dict():
    student = Student("–§–ª–æ–π–¥ –ú—ç–π–≤–µ–∑–µ—Ä", "1977-02-24", "–ë–ò–í–¢-25-2", 4.8)
    student_dict = student.to_dict()
    assert student_dict == {
        'fio': '–§–ª–æ–π–¥ –ú—ç–π–≤–µ–∑–µ—Ä',
        'birthdate': '1977-02-24',
        'group': '–ë–ò–í–¢-25-2',
        'gpa': 4.8
    }

def test_from_dict():
    student_dict = {
        'fio': '–î–∂–æ—Ä–¥–∂ –§–ª–æ–π–¥',
        'birthdate': '1973-10-14',
        'group': '–ë–ò–í–¢-25-3',
        'gpa': 3.9
    }
    student = Student.from_dict(student_dict)
    assert student.fio == "–î–∂–æ—Ä–¥–∂ –§–ª–æ–π–¥"
    assert student.gpa == 3.9
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab08/test_models.png)# python_labs

### –ó–∞–¥–∞–Ω–∏–µ B
```
import json
from typing import List
from .models import Student

def students_to_json(students: List[Student], path: str):
    data = [s.to_dict() for s in students]
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def students_from_json(path: str) -> List[Student]:
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return [Student.from_dict(item) for item in data]
```

## —Ç–µ—Å—Ç
```
import pytest
from src.lab08.serialize import students_to_json, students_from_json

def test_serialization():
    students = students_from_json('src/data/lab08/students_input.json')
    for student in students:
        print(f"{student.fio}, {student.birthdate}, {student.group}, GPA: {student.gpa}")
    students_to_json(students, 'src/data/lab08/students_output.json')
    print("–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ src/data/lab08/students_output.json")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab08/output_test.png)# python_labs
